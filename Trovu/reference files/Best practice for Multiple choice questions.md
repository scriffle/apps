I'll extract the best practices for MC questions from this comprehensive workflow document.

## Best Practices for Multiple Choice Questions

### **Structural Requirements (Haladyna Framework)**

**Format:**
- Use exactly 4 options (A, B, C, D) per question
- Present clear, focused stems
- Each option on a new line, properly indented
- Distribute correct answers evenly across positions (unless software randomizes)

**Grammar & Consistency:**
- All options must be grammatically consistent with the stem
- Maintain parallel grammatical structure across all options
- Ensure similar complexity and detail level in all options

**Prohibited Elements:**
- NO "All of the above" options
- NO "None of the above" options
- NO joke answers or obviously wrong options

---

### **Distractor Quality (CRITICAL)**

**Base on Real Misconceptions:**
- ALL distractors must reflect common misconceptions, incorrect assumptions, or logical errors students actually make
- Each distractor should attract 5-25% of test-takers if well-constructed
- Distractors must be plausible in context, scope, frame, and magnitude

**Avoid:**
- Arbitrary wrong answers
- Out-of-scope choices
- Obviously incorrect options
- Distractors that could be argued as correct

---

### **Answer Balance**

**Length Parity:**
- Correct answer must NOT be systematically longer than distractors
- Avoid the "longest option is correct" pattern
- Similar detail level across all options

---

### **Content Requirements**

**Cognitive Levels (Bloom's Taxonomy):**
- **Remember:** Recall facts, definitions, terminology
- **Understand:** Explain concepts in different words
- **Apply:** Use knowledge in new situations
- **Analyze:** Break down relationships, compare/contrast
- **Evaluate:** Make judgments, assess options
- **Create:** Synthesize solutions (rare in MC format)

**Question Quality:**
- Use novel scenarios/applications (not verbatim from teaching materials)
- For higher-order questions: include scenarios, data, or contexts requiring analysis/evaluation
- Each question should have ONE clearly correct answer
- Avoid ambiguity - question should not be interpretable multiple ways

---

### **Test Blueprint Alignment**

**Validity Requirements:**
- Questions must align with curriculum objectives
- Content coverage should match teaching time/emphasis
- Distribution across topics should reflect instructional priorities
- Cognitive level distribution should match assessment goals

**Example Blueprint Structure:**
| Content Area | % Teaching Time | Remember | Understand | Apply | Analyze | Total Questions |
|--------------|----------------|----------|------------|-------|---------|-----------------|

---

### **Technical Specifications**

**Formatting:**
- Use proper Unicode symbols (Δ, π, ≠, ≤, ≥, μ, °C, ×, ÷, ², ³)
- NOT ASCII approximations
- Proper mathematical/chemical notation throughout

**Presentation:**
- Questions first, ALL together
- Answer key in SEPARATE SECTION after all questions
- Clear cognitive level labels

---

### **Quality Checks**

**Pre-Deployment Verification:**
1. **Factual Accuracy:** Every fact, figure, formula verified against authoritative sources
2. **Clarity:** No ambiguous wording
3. **Validity:** Each question has exactly ONE correct answer
4. **Distractor Check:** All distractors plausible but definitely incorrect
5. **Bias Check:** No cultural assumptions, stereotypes, or insensitive content
6. **Grammar:** No errors, parallel structure maintained

**Common Errors to Catch:**
- Hallucinated facts (plausible but invented)
- Outdated information
- Subtle conceptual errors
- Formula mistakes
- Multiple defensible answers
- Overgeneralization without noting exceptions

---

### **Assessment-Specific Considerations**

**Practice Sets:**
- Include full explanations for correct answers
- Explain why EACH distractor is incorrect
- Provide learning hints/teaching points
- Help students understand misconceptions

**Summative Assessments:**
- Provide teacher answer key with:
  - Correct answer + cognitive level + key concept
  - Misconception each distractor represents
  - Difficulty estimates
  - Item discrimination notes

---

### **Accessibility & Differentiation**

**Simplified Versions:**
- Shorter, simpler sentence structures
- Replace complex vocabulary with everyday terms
- Maintain same cognitive level and content
- Same correct answer and misconception-based distractors

**Extension Versions:**
- Increase cognitive complexity (move up Bloom's levels)
- Multi-step reasoning or synthesis
- More sophisticated contexts
- Advanced but plausible misconceptions

---

### **Critical Reminders**

1. **Human Verification Required:** LLMs can generate plausible but incorrect content - ALL questions must be verified by subject experts
2. **Misconception-Based:** Quality questions diagnose student thinking, not just measure recall
3. **Fair Testing:** Questions should assess learning, not test-taking skills
4. **No Tricks:** Avoid patterns like "C is always correct" or "longest answer wins"
5. **Alignment:** Questions must measure stated learning objectives

---

### **Student Strategies (To Inform Question Design)**

Understanding how students approach questions helps design better ones:
- Students eliminate obviously wrong options first
- They compare remaining options for subtle differences
- They look for grammatical clues (all options should fit grammatically)
- They watch for qualifiers: "always," "never," "sometimes," "usually"
- First instincts are often correct IF they know the content

**Design Implication:** Make all options grammatically consistent and similarly plausible to test knowledge, not test-taking skills.