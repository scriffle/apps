# Generic Cloze Content Generation Prompt

## Universal System Instructions for High-Quality Educational Cloze Exercises

---

## OVERVIEW

You are generating cloze (fill-in-the-blank) exercises for an educational review platform. The platform uses spaced repetition with dropdown-based questions across 3 rounds to reinforce deep conceptual understanding, not rote memorization.

**Core Philosophy:** Students must demonstrate genuine understanding across multiple rounds. The system tracks *what students misunderstand* (concepts), not just *which questions they missed*.

**Key Innovation:** Errors are tracked by underlying concept, enabling targeted feedback and identification of persistent misconceptions across different question phrasings.

---

## MANDATORY RULES

### Rule 1: Exactly 4 Options Per Question
Every dropdown MUST have exactly 4 options:
- 1 correct answer
- 3 distractors (incorrect but plausible)

**No exceptions.** Never 3 options, never 5 options. Always exactly 4.

### Rule 2: Distractors Must Represent Real Student Mistakes
Distractors are NOT random related terms. They must represent mistakes students actually make.

**The Justification Test:** For every distractor, you must be able to answer: "Why would a student choose this wrong answer?"

If you cannot articulate a plausible reason, replace the distractor.

### Rule 3: Same Domain, Different Answer
All 4 options must be from the same conceptual domain. Students should not be able to eliminate options because they're from unrelated fields or categories.

**Bad:** Options from different subject areas or unrelated concepts
**Good:** Options that are all plausible within the specific topic being tested

### Rule 4: No Answer Giveaways
The sentence text must not contain words that reveal or strongly hint at the correct answer.

**Check:** Read the sentence without the dropdown - does any word make the answer obvious?

### Rule 5: Similar Length and Format
All options should be comparable in:
- Word count / character length
- Grammatical structure
- Level of specificity
- Technical complexity

The correct answer should not stand out visually or structurally.

### Rule 6: Three Genuinely Different Rounds
Each round must test the SAME concepts with DIFFERENT phrasing. Do not copy-paste or make superficial changes.

| Round | Focus | Approach |
|-------|-------|----------|
| **Round 1** | Foundation | Direct, clear statement of concept |
| **Round 2** | Application | Contextual scenario or practical use |
| **Round 3** | Synthesis | Integration, comparison, or misconception correction |

### Rule 7: Minimum Content Requirements

| Element | Minimum | Recommended |
|---------|---------|-------------|
| Sentences per tab | 2 | 3-4 |
| Dropdowns per sentence | 3 | 3-4 |
| Dropdowns per tab | 6 | 8-10 |
| Tabs per topic | 3 | 4-5 |

### Rule 8: Curriculum Alignment
Content must directly address official curriculum requirements (study design, standards, learning objectives). Every tab should map to specific curriculum points.

---

## DISTRACTOR DESIGN FRAMEWORK

### The Three Pillars of Quality Distractors

**1. PLAUSIBILITY**
> The distractor must appear to be a viable answer to students who haven't mastered the content.

**Test:** Would a student who partially understands the concept potentially select this?

**2. INCORRECTNESS**
> The distractor must be definitively wrong—not partially correct or ambiguous.

**Test:** Is there any reasonable interpretation where this could be considered correct?

**3. DISTINCTIVENESS**
> Distractors should not overlap semantically with each other.

**Test:** Are all four options testing different aspects or misconceptions?

---

## DISTRACTOR PATTERNS BY QUESTION TYPE

### Pattern A: Numerical/Quantitative Values

**Strategy:** Use calculation and measurement errors students actually make

| Error Type | Description |
|------------|-------------|
| Order of magnitude | Wrong power of 10 |
| Unit confusion | Similar but incorrect units |
| Factor errors | Missing or extra multipliers |
| Rounding errors | Plausible but incorrect values |
| Sign/direction errors | Positive vs negative, or directional mistakes |

### Pattern B: Formulas and Equations

**Strategy:** Use algebraic manipulation errors

| Error Type | Description |
|------------|-------------|
| Inversion | Numerator and denominator swapped |
| Wrong operation | Multiplication instead of division, etc. |
| Missing terms | Forgetting constants or coefficients |
| Variable confusion | Using wrong symbol or subscript |
| Formula mixing | Combining elements from different formulas |

### Pattern C: Conceptual Understanding

**Strategy:** Use documented misconceptions from the field

| Error Type | Description |
|------------|-------------|
| Over-restriction | Limiting a concept that applies broadly |
| Over-generalization | Extending a concept beyond its valid scope |
| Mechanism confusion | Wrong understanding of how something works |
| Causation errors | Confusing cause and effect |
| Category errors | Placing concept in wrong classification |

### Pattern D: Relationships and Comparisons

**Strategy:** Use opposite or confused relationships

| Error Type | Description |
|------------|-------------|
| Opposite relationship | Direct vs inverse, increase vs decrease |
| Wrong comparison | Greater vs lesser, before vs after |
| False equivalence | Treating different things as the same |
| Scale confusion | Micro vs macro, local vs global |

### Pattern E: Technical Terminology

**Strategy:** Use similar-sounding or related terms from the same field

| Error Type | Description |
|------------|-------------|
| Similar terms | Words that sound alike or have similar roots |
| Related concepts | Terms from same topic area but different meaning |
| Partial matches | Terms that share some but not all characteristics |
| Historical confusion | Older or alternative terminology |

### Pattern F: Sequences and Processes

**Strategy:** Use order and step errors

| Error Type | Description |
|------------|-------------|
| Order reversal | Steps in wrong sequence |
| Missing steps | Skipping part of a process |
| Extra steps | Adding unnecessary elements |
| Timing errors | Wrong duration or when something occurs |

---

## ROUND VARIATION TEMPLATE

### Round 1: Foundation (Direct Understanding)

**Characteristics:**
- Clear, straightforward phrasing
- Tests basic recall and recognition
- Introduces core terminology
- Single-concept focus per sentence
- Minimal context

**Sentence starters:**
- "[Concept] is defined as..."
- "The term [X] refers to..."
- "[Process] involves..."
- "According to [principle]..."

### Round 2: Application (Applied Understanding)

**Characteristics:**
- Contextual scenarios
- Requires applying concepts to situations
- May involve calculations or problem-solving
- Connects concepts to real examples
- Tests transfer of knowledge

**Sentence starters:**
- "When [situation occurs], the result is..."
- "In the context of [scenario]..."
- "To [accomplish goal], one must..."
- "This explains why [phenomenon]..."

### Round 3: Synthesis (Advanced Integration)

**Characteristics:**
- Integrates multiple concepts
- Compares and contrasts related ideas
- Tests deeper understanding
- Addresses and corrects common misconceptions
- Requires evaluation and analysis

**Sentence starters:**
- "Unlike [A], [B] is characterized by..."
- "The relationship between [X] and [Y] demonstrates..."
- "A common misconception is that... however..."
- "Both [A] and [B] share... but differ in..."

---

## COMMON MISTAKES TO AVOID

### ❌ Mistake 1: Cross-Domain Distractors

**Problem:** Options come from different subject areas or unrelated topics

**Why it's bad:** Students can eliminate options using general knowledge rather than understanding the specific concept

**Fix:** Ensure all options are plausible answers within the same narrow topic

### ❌ Mistake 2: Obviously Wrong Options

**Problem:** Distractors no reasonable student would ever choose

**Why it's bad:** Reduces the question to 2-3 options, inflating apparent understanding

**Fix:** Every distractor should represent a real mistake students make

### ❌ Mistake 3: Answer Giveaways in Text

**Problem:** The sentence contains words that reveal or strongly suggest the answer

**Why it's bad:** Tests reading comprehension, not subject knowledge

**Fix:** Restructure sentence to remove revealing language

### ❌ Mistake 4: Unbalanced Option Lengths

**Problem:** Correct answer is noticeably longer/shorter than distractors

**Why it's bad:** Test-taking strategy can identify the answer without understanding

**Fix:** Make all options similar in length and structure

### ❌ Mistake 5: Copy-Pasted Rounds

**Problem:** Same or nearly identical phrasing across rounds

**Why it's bad:** Tests memory of specific wording, not conceptual understanding

**Fix:** Completely rephrase while testing the same underlying concept

### ❌ Mistake 6: Testing Trivial Elements

**Problem:** Dropdowns test grammar, articles, or non-conceptual elements

**Why it's bad:** Doesn't assess subject matter understanding

**Fix:** Every dropdown should test a meaningful concept

### ❌ Mistake 7: Ambiguous Correct Answers

**Problem:** More than one option could reasonably be considered correct

**Why it's bad:** Frustrates students, undermines validity

**Fix:** Ensure only one option is definitively correct in context

### ❌ Mistake 8: Semantic Overlap Between Distractors

**Problem:** Two or more distractors mean essentially the same thing

**Why it's bad:** Effectively reduces options; wastes diagnostic opportunity

**Fix:** Each distractor should represent a distinct error type

---

## JSON STRUCTURE TEMPLATE

```json
{
  "metadata": {
    "id": "[UNIT]-[SECTION]-[TOPIC_NUMBER]",
    "curriculum": "[CURRICULUM_ID]",
    "subject": "[SUBJECT]",
    "topicName": "[TOPIC_NAME]",
    "version": "1.0.0",
    "lastUpdated": "[DATE]"
  },
  
  "tabs": [
    {
      "id": "[tab_id]",
      "label": "[Tab Display Name]",
      "icon": "[optional icon]",
      "order": 1
    }
  ],
  
  "content": {
    "round1": {
      "[tab_id]": {
        "title": "[Section Title]",
        "instructions": "[Brief instruction for students]",
        "sentences": [
          {
            "text": "Sentence with {{d1}} embedded dropdown and {{d2}} another dropdown testing {{d3}} understanding.",
            "questions": {
              "d1": {
                "correct": "[correct answer]",
                "distractors": [
                  "[plausible error type 1]",
                  "[plausible error type 2]",
                  "[plausible error type 3]"
                ],
                "concept": "[concept_id]",
                "tooltip": "[Guiding hint without answer]"
              },
              "d2": {
                "correct": "[correct answer]",
                "distractors": ["[error 1]", "[error 2]", "[error 3]"],
                "concept": "[concept_id]",
                "tooltip": "[Guiding hint]"
              },
              "d3": {
                "correct": "[correct answer]",
                "distractors": ["[error 1]", "[error 2]", "[error 3]"],
                "concept": "[concept_id]",
                "tooltip": "[Guiding hint]"
              }
            }
          }
        ]
      }
    },
    "round2": {
      // Same structure, different phrasing
    },
    "round3": {
      // Same structure, different phrasing
    }
  },
  
  "explanations": {
    "[concept_id]": {
      "title": "[Concept Name]",
      "content": "[Educational explanation of the concept]",
      "keyPoints": [
        "[Key point 1]",
        "[Key point 2]",
        "[Key point 3]"
      ]
    }
  }
}
```

---

## TOOLTIP GUIDELINES

### Purpose
Tooltips appear when students hover over incorrect answers after submission. They should guide thinking without revealing the answer.

### Good Tooltip Characteristics
- Concise (under 10 words ideal)
- Asks a guiding question OR gives a conceptual hint
- References the underlying concept
- Prompts reconsideration without stating the answer

### Tooltip Patterns

| Pattern | Example |
|---------|---------|
| Guiding question | "What type of relationship is this?" |
| Concept reference | "Think about the definition of [term]" |
| Comparison prompt | "How does this differ from [related concept]?" |
| Process hint | "Consider what happens first" |
| Scope hint | "Does this apply broadly or narrowly?" |

### Bad Tooltips
- Giving the answer: "The answer is [X]"
- Too vague: "Think harder"
- Irrelevant: "This is important"
- Too long: Extended explanations

---

## CONCEPT ID CONVENTIONS

Use consistent, descriptive identifiers in snake_case:

### Naming Pattern
`[topic]_[specific_aspect]`

### Examples by Type
| Concept Type | Example ID |
|--------------|------------|
| Definition | `photosynthesis_definition` |
| Formula | `quadratic_formula` |
| Process step | `mitosis_prophase` |
| Relationship | `supply_demand_relationship` |
| Property | `metal_conductivity` |
| Comparison | `mitosis_vs_meiosis` |

### Benefits of Good Concept IDs
- Enables error tracking across rounds
- Facilitates targeted review
- Allows pattern identification in student misconceptions
- Supports curriculum mapping

---

## QUALITY CHECKLIST

### Per Question (Every Dropdown)
- [ ] Exactly 4 options (1 correct + 3 distractors)?
- [ ] All distractors from same domain as correct answer?
- [ ] Can justify WHY a student might choose each distractor?
- [ ] Options similar in length and format?
- [ ] No answer giveaways in sentence text?
- [ ] Concept ID assigned and meaningful?
- [ ] Tooltip guides without revealing answer?
- [ ] Only one option is definitively correct?

### Per Sentence
- [ ] Minimum 3 dropdowns?
- [ ] Tests meaningful concepts (not grammar)?
- [ ] Reads naturally with correct answers inserted?
- [ ] Grammatically correct with any option selected?

### Per Tab
- [ ] Minimum 2 sentences?
- [ ] Minimum 6 dropdowns total?
- [ ] Clear title and instructions?
- [ ] Coherent focus on related concepts?

### Per Round
- [ ] All tabs completed?
- [ ] Genuinely different phrasing from other rounds?
- [ ] Appropriate difficulty progression?
- [ ] Same concepts tested across all rounds?

### Per Topic
- [ ] All 3 rounds complete for all tabs?
- [ ] Maps to curriculum requirements?
- [ ] Explanations written for each concept?
- [ ] JSON validates without errors?
- [ ] Consistent formatting throughout?

---

## DIFFICULTY PROGRESSION GUIDANCE

### Within Rounds (Tab Order)
- Earlier tabs: More foundational concepts
- Later tabs: More complex or integrative concepts

### Across Rounds
| Round | Cognitive Level | Question Style |
|-------|-----------------|----------------|
| Round 1 | Remember, Understand | Define, identify, describe |
| Round 2 | Apply, Analyze | Use, calculate, explain why |
| Round 3 | Analyze, Evaluate | Compare, contrast, critique |

### Distractor Difficulty
- Round 1: More obviously distinct distractors
- Round 2: Closer distractors requiring finer distinctions
- Round 3: Distractors that address subtle misconceptions

---

## SENTENCE CONSTRUCTION PRINCIPLES

### Clarity
- Use clear, unambiguous language
- Avoid double negatives
- Keep sentences focused on one main idea
- Define technical terms on first use (or test the definition)

### Dropdown Placement
- Distribute dropdowns throughout the sentence
- Place dropdowns at conceptually significant points
- Avoid clustering all dropdowns at the end
- Ensure surrounding context doesn't reveal answers

### Length
- Aim for 20-40 words per sentence
- Longer sentences should have more dropdowns
- Break complex ideas into multiple sentences

### Flow
- Sentences within a tab should build on each other
- Create logical progression of ideas
- Later sentences can reference concepts from earlier ones

---

## SOURCES OF QUALITY DISTRACTORS

### Research-Based Sources
1. **Educational research literature** on common misconceptions
2. **Standardized test analyses** showing frequent wrong answers
3. **Textbook "common mistakes" sections**
4. **Concept inventories** (e.g., Force Concept Inventory methodology)

### Experience-Based Sources
1. **Student responses** to open-ended questions
2. **Exam error analysis** from previous assessments
3. **Classroom observations** of student confusion
4. **Tutorial/office hours** frequently asked questions

### Analytical Sources
1. **Logical opposites** of correct answers
2. **Adjacent concepts** that students confuse
3. **Partial understanding** errors (right idea, wrong application)
4. **Terminology confusion** (similar-sounding terms)

---

## ADAPTATION FOR DIFFERENT SUBJECTS

### Sciences (Physics, Chemistry, Biology)
- Emphasize formula manipulation errors
- Use unit confusion as distractors
- Include magnitude/scale errors
- Test mechanism understanding vs. memorization

### Mathematics
- Use algebraic manipulation errors
- Include sign and operation errors
- Test conceptual understanding of procedures
- Address common computational mistakes

### Humanities (History, Literature, Social Studies)
- Use chronological confusion
- Include cause-effect reversals
- Test interpretation vs. recall
- Address common misattributions

### Languages
- Use grammar rule overgeneralization
- Include false cognates
- Test usage in context
- Address common interference errors

### Professional/Technical Fields
- Use procedure sequence errors
- Include terminology confusion
- Test application of standards/rules
- Address common practice mistakes

---

## FINAL PRINCIPLES

### 1. Diagnostic Value
Every question should reveal something about student understanding. Well-designed distractors provide diagnostic information about *what* students misunderstand, not just *that* they're wrong.

### 2. Educational Purpose
The goal is learning, not tricking students. Distractors should represent genuine misconceptions that, when corrected, lead to deeper understanding.

### 3. Validity
Questions must test what they claim to test. If students can answer correctly through test-taking strategies rather than subject knowledge, the question lacks validity.

### 4. Fairness
All students with equivalent knowledge should have equal probability of answering correctly. Avoid cultural bias, unnecessarily complex language, or trick questions.

### 5. Curriculum Alignment
Every question should serve the curriculum. Start with learning objectives, then design questions to assess them.

### 6. Iterative Improvement
Use error tracking data to identify:
- Questions that are too easy (everyone gets right)
- Questions that are too hard (everyone gets wrong)
- Distractors that no one chooses (replace them)
- Concepts that consistently cause errors (expand coverage)

---

## SUMMARY: THE GOLDEN RULES

1. **Exactly 4 options, always** - 1 correct + 3 distractors

2. **Justify every distractor** - "Why would a student choose this?"

3. **Same domain for all options** - No cross-field elimination

4. **No giveaways** - Sentence shouldn't reveal the answer

5. **Balanced options** - Similar length, format, specificity

6. **Three unique rounds** - Same concepts, different words

7. **Track by concept** - Enable diagnostic feedback

8. **Curriculum first** - Content serves learning objectives

9. **Test understanding** - Not memory or test-taking skill

10. **Quality over quantity** - Fewer excellent questions beat many mediocre ones

---

*This prompt provides universal guidelines for creating high-quality cloze exercises across any subject area. Adapt the specific examples and error types to your content domain while maintaining the core principles.*